{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SupervisedClustering Usage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SupervisedClustering --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from PyMachineLearning.preprocessing import encoder, imputer, scaler, features_selector\n",
    "from PyMachineLearning.evaluation import SimpleEvaluation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from  xgboost import XGBRegressor\n",
    "from SupervisedClustering.models import FastKmedoidsEstimator, KFoldFastKmedoidsEstimator, KmeansEstimator, MiniBatchKmeansEstimator\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(df):\n",
    "    columns_to_exclude = ['', 'id','sq_mt_allotment','floor', 'neighborhood', 'district'] \n",
    "    df = df.select(pl.exclude(columns_to_exclude))\n",
    "    binary_cols = ['is_renewal_needed', 'has_lift', 'is_exterior', 'has_parking']\n",
    "    multi_cols = ['energy_certificate', 'house_type']\n",
    "    quant_cols = [x for x in df.columns if x not in binary_cols + multi_cols]\n",
    "    encoding = encoder(method='ordinal')\n",
    "    encoded_arr = encoding.fit_transform(df[binary_cols + multi_cols])\n",
    "    cat_df = pl.DataFrame(encoded_arr)\n",
    "    cat_df.columns =  binary_cols + multi_cols\n",
    "    cat_df = cat_df.with_columns([pl.col(col).cast(pl.Int64) for col in cat_df.columns])\n",
    "    quant_df = df[quant_cols]\n",
    "    df = pl.concat([quant_df, cat_df], how='horizontal')\n",
    "    response = 'buy_price'\n",
    "    quant_predictors = [x for x in quant_cols if x != response]\n",
    "    binary_predictors = [x for x in binary_cols if x != response]\n",
    "    multi_predictors = [x for x in multi_cols if x != response]\n",
    "    cat_predictors = binary_predictors + multi_predictors\n",
    "    p1, p2, p3 = len(quant_predictors), len(binary_predictors), len(multi_predictors)\n",
    "    return df, p1, p2, p3, response, quant_predictors, cat_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_houses_df = pl.read_csv('madrid_houses.csv')\n",
    "madrid_houses_df, p1, p2, p3, response, quant_predictors, cat_predictors = processing(madrid_houses_df)\n",
    "predictors = quant_predictors + cat_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sq_mt_built</th><th>n_rooms</th><th>n_bathrooms</th><th>n_floors</th><th>buy_price</th><th>is_renewal_needed</th><th>has_lift</th><th>is_exterior</th><th>has_parking</th><th>energy_certificate</th><th>house_type</th></tr><tr><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>64.0</td><td>2</td><td>1</td><td>1</td><td>85000</td><td>0</td><td>0</td><td>1</td><td>0</td><td>4</td><td>0</td></tr><tr><td>70.0</td><td>3</td><td>1</td><td>1</td><td>129900</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>94.0</td><td>2</td><td>2</td><td>1</td><td>144247</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>64.0</td><td>2</td><td>1</td><td>1</td><td>109900</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>108.0</td><td>2</td><td>2</td><td>1</td><td>260000</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌────────────┬─────────┬────────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ sq_mt_buil ┆ n_rooms ┆ n_bathroom ┆ n_floors ┆ … ┆ is_exteri ┆ has_parki ┆ energy_ce ┆ house_typ │\n",
       "│ t          ┆ ---     ┆ s          ┆ ---      ┆   ┆ or        ┆ ng        ┆ rtificate ┆ e         │\n",
       "│ ---        ┆ i64     ┆ ---        ┆ i64      ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64        ┆         ┆ i64        ┆          ┆   ┆ i64       ┆ i64       ┆ i64       ┆ i64       │\n",
       "╞════════════╪═════════╪════════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 64.0       ┆ 2       ┆ 1          ┆ 1        ┆ … ┆ 1         ┆ 0         ┆ 4         ┆ 0         │\n",
       "│ 70.0       ┆ 3       ┆ 1          ┆ 1        ┆ … ┆ 1         ┆ 0         ┆ 0         ┆ 0         │\n",
       "│ 94.0       ┆ 2       ┆ 2          ┆ 1        ┆ … ┆ 1         ┆ 0         ┆ 0         ┆ 0         │\n",
       "│ 64.0       ┆ 2       ┆ 1          ┆ 1        ┆ … ┆ 1         ┆ 0         ┆ 0         ┆ 0         │\n",
       "│ 108.0      ┆ 2       ┆ 2          ┆ 1        ┆ … ┆ 1         ┆ 1         ┆ 0         ┆ 0         │\n",
       "└────────────┴─────────┴────────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madrid_houses_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = madrid_houses_df[predictors].to_pandas()\n",
    "Y = madrid_houses_df[response].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.75, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clustering estimators usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastKmedoidsEstimator(BaseEstimator, RegressorMixin) :\n",
    "    \"\"\"\n",
    "    Implements the Fast-K-medoids-Estimator based on Fast-K-medoids and Sklearn estimators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimators, n_clusters, method='pam', init='heuristic', max_iter=100, random_state=123,\n",
    "                    frac_sample_size=0.1, p1=None, p2=None, p3=None, d1='robust_mahalanobis', d2='jaccard', d3='matching', \n",
    "                    robust_maha_method='trimmed', alpha=0.05, epsilon=0.05, n_iters=20, q=1,\n",
    "                    fast_VG=False, VG_sample_size=1000, VG_n_samples=5, y_type=None) :\n",
    "        \"\"\"\n",
    "        Constructor method.\n",
    "        \n",
    "        Parameters:\n",
    "            estimators: a dictionary with the sklearn estimators (single models or pipelines) to be used in each clusters (keys: cluster indexes, values: estimators initialized).\n",
    "            n_clusters: the number of clusters.\n",
    "            method: the k-medoids clustering method. Must be in ['pam', 'alternate']. PAM is the classic one, more accurate but slower.\n",
    "            init: the k-medoids initialization method. Must be in ['heuristic', 'random']. Heuristic is the classic one, smarter burt slower.\n",
    "            max_iter: the maximum number of iterations run by k-medodis.\n",
    "            frac_sample_size: the sample size in proportional terms.\n",
    "            p1, p2, p3: number of quantitative, binary and multi-class variables in the considered data matrix, respectively. Must be a non negative integer.\n",
    "            d1: name of the distance to be computed for quantitative variables. Must be an string in ['euclidean', 'minkowski', 'canberra', 'mahalanobis', 'robust_mahalanobis']. \n",
    "            d2: name of the distance to be computed for binary variables. Must be an string in ['sokal', 'jaccard'].\n",
    "            d3: name of the distance to be computed for multi-class variables. Must be an string in ['matching'].\n",
    "            q: the parameter that defines the Minkowski distance. Must be a positive integer.\n",
    "            robust_maha_method: the method to be used for computing the robust covariance matrix. Only needed when d1 = 'robust_mahalanobis'.\n",
    "            alpha : a real number in [0,1] that is used if `method` is 'trimmed' or 'winsorized'. Only needed when d1 = 'robust_mahalanobis'.\n",
    "            epsilon: parameter used by the Delvin algorithm that is used when computing the robust covariance matrix. Only needed when d1 = 'robust_mahalanobis'.\n",
    "            n_iters: maximum number of iterations used by the Delvin algorithm. Only needed when d1 = 'robust_mahalanobis'.\n",
    "            fast_VG: whether the geometric variability estimation will be full (False) or fast (True).\n",
    "            VG_sample_size: sample size to be used to make the estimation of the geometric variability.\n",
    "            VG_n_samples: number of samples to be used to make the estimation of the geometric variability.\n",
    "            random_state: the random seed used for the (random) sample elements.\n",
    "            y_type: the type of response variable. Must be in ['quantitative', 'binary', 'multiclass'].\n",
    "        \"\"\" \n",
    "    def set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Set params method: for setting params properly.\n",
    "        \n",
    "        Parameters:\n",
    "            params: a dictionary with params as values and params keys as names, following the sklearn conventions.\n",
    "        \"\"\"   \n",
    "    def fit(self, X, y, weights=None):\n",
    "        \"\"\"\n",
    "        Fit method: fitting the Fast KMedoids algorithm to `X` (and `y` if needed).\n",
    "        \n",
    "        Parameters:\n",
    "            X: a Pandas or Polars data-frame or a NumPy array. Represents a predictors matrix. Is required.\n",
    "            y: a Pandas or Polars series or a NumPy array. Represents a response variable. Is required.\n",
    "            weights: the sample weights, if exists.\n",
    "        \"\"\"  \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict method: predicting the response variable for `X`.\n",
    "\n",
    "        Parameters:\n",
    "            X: a pandas/polars data-frame or a numpy array. Represents a predictors matrix. Is required.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldFastKmedoidsEstimator(BaseEstimator, RegressorMixin) :\n",
    "    \"\"\"\n",
    "    Implements the KFold-Fast-K-medoids-Estimator based on KFold-Fast-K-medoids and Sklearn estiamators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimators, n_clusters, method='pam', init='heuristic', max_iter=100, random_state=123,\n",
    "                        frac_sample_size=0.1, p1=None, p2=None, p3=None, d1='robust_mahalanobis', d2='jaccard', d3='matching', \n",
    "                        robust_maha_method='trimmed', alpha=0.05, epsilon=0.05, n_iters=20, q=1,\n",
    "                        fast_VG=False, VG_sample_size=1000, VG_n_samples=5, \n",
    "                        n_splits=5, shuffle=True, kfold_random_state=123, y_type=None, verbose=True) :\n",
    "            \"\"\"\n",
    "            Constructor method.\n",
    "            \n",
    "            Parameters:\n",
    "                estimators: a dictionary with the sklearn estimators (single models or pipelines) to be used in each clusters (keys: cluster indexes, values: estimators initialized).\n",
    "                n_clusters: the number of clusters.\n",
    "                method: the k-medoids clustering method. Must be in ['pam', 'alternate']. PAM is the classic one, more accurate but slower.\n",
    "                init: the k-medoids initialization method. Must be in ['heuristic', 'random']. Heuristic is the classic one, smarter burt slower.\n",
    "                max_iter: the maximum number of iterations run by k-medodis.\n",
    "                frac_sample_size: the sample size in proportional terms.\n",
    "                p1, p2, p3: number of quantitative, binary and multi-class variables in the considered data matrix, respectively. Must be a non negative integer.\n",
    "                d1: name of the distance to be computed for quantitative variables. Must be an string in ['euclidean', 'minkowski', 'canberra', 'mahalanobis', 'robust_mahalanobis']. \n",
    "                d2: name of the distance to be computed for binary variables. Must be an string in ['sokal', 'jaccard'].\n",
    "                d3: name of the distance to be computed for multi-class variables. Must be an string in ['matching'].\n",
    "                q: the parameter that defines the Minkowski distance. Must be a positive integer.\n",
    "                robust_maha_method: the method to be used for computing the robust covariance matrix. Only needed when d1 = 'robust_mahalanobis'.\n",
    "                alpha : a real number in [0,1] that is used if `method` is 'trimmed' or 'winsorized'. Only needed when d1 = 'robust_mahalanobis'.\n",
    "                epsilon: parameter used by the Delvin algorithm that is used when computing the robust covariance matrix. Only needed when d1 = 'robust_mahalanobis'.\n",
    "                n_iters: maximum number of iterations used by the Delvin algorithm. Only needed when d1 = 'robust_mahalanobis'.\n",
    "                fast_VG: whether the geometric variability estimation will be full (False) or fast (True).\n",
    "                VG_sample_size: sample size to be used to make the estimation of the geometric variability.\n",
    "                VG_n_samples: number of samples to be used to make the estimation of the geometric variability.\n",
    "                random_state: the random seed used for the (random) sample elements.\n",
    "                y_type: the type of response variable. Must be in ['quantitative', 'binary', 'multiclass'].\n",
    "                n_splits: number of folds to be used.\n",
    "                shuffle: whether data is shuffled before applying KFold or not, must be in [True, False]. \n",
    "                kfold_random_state: the random seed for KFold if shuffle = True.\n",
    "            \"\"\"  \n",
    "    def set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Set params method: for setting params properly.\n",
    "        \n",
    "        Parameters:\n",
    "            params: a dictionary with params as values and params keys as names, following the sklearn conventions.\n",
    "        \"\"\"\n",
    "    def fit(self, X, y, weights=None):\n",
    "        \"\"\"\n",
    "        Fit method: fitting the KFold Fast KMedoids algorithm to `X` (and `y` if needed).\n",
    "        \n",
    "        Parameters:\n",
    "            X: a Pandas or Polars data-frame or a NumPy array. Represents a predictors matrix. Is required.\n",
    "            y: a Pandas or Polars series or a NumPy array. Represents a response variable. Is required.\n",
    "            weights: the sample weights, if exists.\n",
    "        \"\"\" \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict method: predicting the response variable for `X`.\n",
    "\n",
    "        Parameters:\n",
    "            X: a pandas/polars data-frame or a numpy array. Represents a predictors matrix. Is required.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KmeansEstimator(BaseEstimator, RegressorMixin, ClusterMixin):\n",
    "    \"\"\"\n",
    "    Implements the K-means-Estimator based on K-means and Sklearn estimators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimators, n_clusters, random_state=123):\n",
    "        \"\"\"\n",
    "        Constructor method.\n",
    "        \n",
    "        Parameters:\n",
    "            estimators: a dictionary with the sklearn estimators (single models or pipelines) to be used in each clusters (keys: cluster indexes, values: estimators initialized).\n",
    "            n_clusters: the number of clusters.\n",
    "            random_state: the random seed used for the (random) sample elements.\n",
    "        \"\"\"  \n",
    "    def set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Set params method: for setting params properly.\n",
    "        \n",
    "        Parameters:\n",
    "            params: a dictionary with params as values and params keys as names, following the sklearn conventions.\n",
    "        \"\"\"   \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit method: fitting the KMeans algorithm to `X` (and `y` if needed).\n",
    "        \n",
    "        Parameters:\n",
    "            X: a Pandas or Polars data-frame or a NumPy array. Represents a predictors matrix. Is required.\n",
    "            y: a Pandas or Polars series or a NumPy array. Represents a response variable. Is required.\n",
    "            weights: the sample weights, if exists.\n",
    "        \"\"\" \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict method: predicting the response variable for `X`.\n",
    "\n",
    "        Parameters:\n",
    "            X: a pandas/polars data-frame or a numpy array. Represents a predictors matrix. Is required.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchKmeansEstimator(BaseEstimator, RegressorMixin, ClusterMixin):\n",
    "    \"\"\"\n",
    "    Implements the Mini Batch K-means-Estimator based on K-means and Sklearn estimators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimators, n_clusters, random_state=123):\n",
    "        \"\"\"\n",
    "        Constructor method.\n",
    "        \n",
    "        Parameters:\n",
    "            estimators: a dictionary with the sklearn estimators (single models or pipelines) to be used in each clusters (keys: cluster indexes, values: estimators initialized).\n",
    "            n_clusters: the number of clusters.\n",
    "            random_state: the random seed used for the (random) sample elements.\n",
    "        \"\"\"  \n",
    "    def set_params(self, **params):\n",
    "        \"\"\"\n",
    "        Set params method: for setting params properly.\n",
    "        \n",
    "        Parameters:\n",
    "            params: a dictionary with params as values and params keys as names, following the sklearn conventions.\n",
    "        \"\"\"   \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit method: fitting the Mini Batch KMeans algorithm to `X` (and `y` if needed).\n",
    "        \n",
    "        Parameters:\n",
    "            X: a Pandas or Polars data-frame or a NumPy array. Represents a predictors matrix. Is required.\n",
    "            y: a Pandas or Polars series or a NumPy array. Represents a response variable. Is required.\n",
    "            weights: the sample weights, if exists.\n",
    "        \"\"\" \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict method: predicting the response variable for `X`.\n",
    "\n",
    "        Parameters:\n",
    "            X: a pandas/polars data-frame or a numpy array. Represents a predictors matrix. Is required.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_models = {'XGB': XGBRegressor(random_state=123),\n",
    "               'RF': RandomForestRegressor(random_state=123)}\n",
    "\n",
    "clusters_RF = [0,2,4]\n",
    "clusters_XGB = [1,3]\n",
    "\n",
    "estimators_RF_XGB = {j: meta_models['RF'] for j in clusters_RF}\n",
    "estimators_RF_XGB.update({j: meta_models['XGB'] for j in clusters_XGB}) \n",
    "\n",
    "fast_kmedoids_estimator = FastKmedoidsEstimator(estimators=estimators_RF_XGB, \n",
    "                                                n_clusters=2, method='pam', init='heuristic', max_iter=100, \n",
    "                                                random_state=123,  frac_sample_size=0.015, \n",
    "                                                p1=p1, p2=p2, p3=p3, \n",
    "                                                d1='robust_mahalanobis', d2='jaccard', d3='matching', q=1,\n",
    "                                                robust_maha_method='trimmed', alpha=0.05, \n",
    "                                                y_type='quantitative')\n",
    "\n",
    "kfold_fast_kmedoids_estimator = KFoldFastKmedoidsEstimator(estimators=estimators_RF_XGB, \n",
    "                                                           n_clusters=2, method='pam', init='heuristic', max_iter=100, \n",
    "                                                           random_state=123,  frac_sample_size=0.015, \n",
    "                                                           p1=p1, p2=p2, p3=p3, \n",
    "                                                           d1='robust_mahalanobis', d2='jaccard', d3='matching', q=1,\n",
    "                                                           robust_maha_method='trimmed', alpha=0.05, \n",
    "                                                           n_splits=10, shuffle=True, kfold_random_state=123,\n",
    "                                                           y_type='quantitative')\n",
    "\n",
    "kmeans_estimator = KmeansEstimator(estimators=estimators_RF_XGB, n_clusters=2, random_state=123)\n",
    "\n",
    "minibach_kmeans_estimator = MiniBatchKmeansEstimator(estimators=estimators_RF_XGB, n_clusters=2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix size: (244, 244)\n",
      "Num.Clusters: 2. Clusters proportions: [0.6890947 0.3109053]\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "Fast-Kmedoids Estimator: MAE = 188007.61\n"
     ]
    }
   ],
   "source": [
    "fast_kmedoids_estimator.fit(X=X, y=Y)\n",
    "Y_test_hat = fast_kmedoids_estimator.predict(X=X_test)\n",
    "print('\\n-----------------------------------------\\n\\nFast-Kmedoids Estimator:', f'MAE = {np.round(mean_absolute_error(y_pred=Y_test_hat, y_true=Y_test),2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num.Folds: 10. Fold size: 1630.\n",
      "Distance matrix size: 25 (0.015*1630) \n",
      "Clustering Fold 0\n",
      "Distance matrix size: (24, 24)\n",
      "Clustering Fold 1\n",
      "Distance matrix size: (24, 24)\n",
      "Clustering Fold 2\n",
      "Distance matrix size: (24, 24)\n",
      "Clustering Fold 3\n",
      "Distance matrix size: (24, 24)\n",
      "Clustering Fold 4\n",
      "Distance matrix size: (24, 24)\n",
      "Clustering Fold 5\n",
      "Distance matrix size: (24, 24)\n",
      "Clustering Fold 6\n",
      "Distance matrix size: (24, 24)\n",
      "Clustering Fold 7\n",
      "Distance matrix size: (24, 24)\n",
      "Clustering Fold 8\n",
      "Distance matrix size: (24, 24)\n",
      "Clustering Fold 9\n",
      "Distance matrix size: (24, 24)\n",
      "X_medoids size: (20, 11)\n",
      "Distance matrix size: (16, 16)\n",
      "Num.Clusters: 2. Clusters proportions: [0.86015702 0.13984298]\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "KFold-Fast-Kmedoids Estimator: MAE = 187685.45\n"
     ]
    }
   ],
   "source": [
    "kfold_fast_kmedoids_estimator.fit(X=X_train, y=Y_train)\n",
    "Y_test_hat = kfold_fast_kmedoids_estimator.predict(X=X_test)\n",
    "print('\\n-----------------------------------------\\n\\nKFold-Fast-Kmedoids Estimator:', f'MAE = {np.round(mean_absolute_error(y_pred=Y_test_hat, y_true=Y_test),2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters proportions: [0.87794406 0.12205594]\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "KMeans Estimator: MAE = 194640.46\n"
     ]
    }
   ],
   "source": [
    "kmeans_estimator.fit(X=X_train, y=Y_train)\n",
    "Y_test_hat = kmeans_estimator.predict(X=X_test)\n",
    "print('\\n-----------------------------------------\\n\\nKMeans Estimator:', f'MAE = {np.round(mean_absolute_error(y_pred=Y_test_hat, y_true=Y_test),2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters weights (proportions): [0.87315996 0.12684004]\n",
      "\n",
      "-----------------------------------------\n",
      "\n",
      "MiniBatch-KMeans Estimator: MAE = 193026.66\n"
     ]
    }
   ],
   "source": [
    "minibach_kmeans_estimator.fit(X=X_train, y=Y_train)\n",
    "Y_test_hat = minibach_kmeans_estimator.predict(X=X_test)\n",
    "print('\\n-----------------------------------------\\n\\nMiniBatch-KMeans Estimator:', f'MAE = {np.round(mean_absolute_error(y_pred=Y_test_hat, y_true=Y_test),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clustering estimators usage with pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_houses_df = pl.read_csv('madrid_houses_NaNs.csv')\n",
    "madrid_houses_df, p1, p2, p3, response, quant_predictors, cat_predictors = processing(madrid_houses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = madrid_houses_df[predictors].to_pandas()\n",
    "Y = madrid_houses_df[response].to_pandas()\n",
    "# The Null values of the Polars columns that are define as Object type by Pandas are treated as None and not as NaN (what we would like)\n",
    "# The avoid this behavior the next step is necessary\n",
    "X = X.fillna(value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = KFold(n_splits=4, shuffle=True, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_pipeline = Pipeline([('imputer', imputer(apply=True)),\n",
    "                           ('scaler', scaler())\n",
    "                          ])\n",
    "\n",
    "cat_pipeline = Pipeline([('encoder', encoder(method='ordinal')),\n",
    "                         ('imputer', imputer(apply=True))\n",
    "                        ])\n",
    "\n",
    "quant_cat_preprocessing = ColumnTransformer(transformers=[('quant', quant_pipeline, quant_predictors),\n",
    "                                                          ('cat', cat_pipeline, cat_predictors)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_models = {'XGB': XGBRegressor(random_state=123),\n",
    "               'RF': RandomForestRegressor(random_state=123)}\n",
    "\n",
    "clusters_RF = [0,2,4]\n",
    "clusters_XGB = [1,3]\n",
    "max_n_clusters = len(clusters_RF + clusters_XGB)\n",
    "\n",
    "estimators_RF_XGB = {j: meta_models['RF'] for j in clusters_RF}\n",
    "estimators_RF_XGB.update({j: meta_models['XGB'] for j in clusters_XGB}) \n",
    "\n",
    "fast_kmedoids_estimator = FastKmedoidsEstimator(estimators=estimators_RF_XGB, \n",
    "                                                    n_clusters=2, method='pam', init='heuristic', max_iter=100, \n",
    "                                                    random_state=123,  frac_sample_size=0.015, \n",
    "                                                    p1=p1, p2=p2, p3=p3, \n",
    "                                                    d1='robust_mahalanobis', d2='jaccard', d3='matching', q=1,\n",
    "                                                    robust_maha_method='trimmed', alpha=0.05, \n",
    "                                                    y_type='quantitative')\n",
    "\n",
    "pipeline_fast_kmedoids_estimator = Pipeline([('preprocessing', quant_cat_preprocessing),\n",
    "                                             ('features_selector', features_selector()),\n",
    "                                             ('clustering_model', fast_kmedoids_estimator)\n",
    "                                            ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_param_grid(trial):\n",
    "\n",
    "    # Fix Grid\n",
    "    param_grid = {\n",
    "        'preprocessing__quant__imputer__method': trial.suggest_categorical('preprocessing__quant__imputer__method', ['simple_mean', 'simple_median', 'iterative_mean', 'iterative_median']),\n",
    "        'preprocessing__cat__imputer__method': trial.suggest_categorical('preprocessing__cat__imputer__method', ['simple_most_frequent']),\n",
    "        'preprocessing__quant__scaler__apply': trial.suggest_categorical('preprocessing__quant__scaler__apply', [True, False]),\n",
    "        'preprocessing__cat__encoder__method': trial.suggest_categorical('preprocessing__cat__encoder__method', ['ordinal']),  # with FastKmedoids only ordinal is suitable\n",
    "        'features_selector__apply': trial.suggest_categorical('features_selector__apply', [False]) # with FastKmedoids we must not select predictors\n",
    "        }\n",
    "\n",
    "    # Conditioned Grid\n",
    "    if param_grid['features_selector__apply'] == True:\n",
    "\n",
    "        param_grid.update({'features_selector__method': trial.suggest_categorical('features_selector__method', ['Fpr_f_reg', 'Fdr_f_reg'])})\n",
    "        \n",
    "    if param_grid['preprocessing__quant__scaler__apply'] == True:\n",
    "    \n",
    "        param_grid.update({'preprocessing__quant__scaler__method': trial.suggest_categorical('preprocessing__quant__scaler__method', ['standard', 'min-max'])})\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grid_clustering_model(trial):\n",
    "\n",
    "    param_grid = {\n",
    "        'clustering_model__n_clusters': trial.suggest_categorical('clustering_model__n_clusters', [2, 3, 4, 5]),\n",
    "        'clustering_model__method': trial.suggest_categorical('clustering_model__method', ['pam', 'alternate']),\n",
    "        'clustering_model__init': trial.suggest_categorical('clustering_model__init', ['random', 'heuristic', 'k-medoids++']),\n",
    "        'clustering_model__frac_sample_size': trial.suggest_categorical('clustering_model__frac_sample_size', [0.01, 0.015, 0.02, 0.03]),\n",
    "        'clustering_model__d1': trial.suggest_categorical('clustering_model__d1', ['robust_mahalanobis', 'mahalanobis', 'euclidean', 'minkowski', 'canberra']),\n",
    "        'clustering_model__d2': trial.suggest_categorical('clustering_model__d2', ['jaccard', 'sokal'])\n",
    "    }\n",
    "\n",
    "    if param_grid['clustering_model__d1'] == 'robust_mahalanobis':\n",
    "\n",
    "        param_grid.update({\n",
    "            'clustering_model__robust_maha_method': trial.suggest_categorical('clustering_model__robust_maha_method', ['trimmed', 'winsorized', 'MAD']),\n",
    "            })\n",
    "\n",
    "        if param_grid['clustering_model__robust_maha_method'] in ['trimmed', 'winsorized']:\n",
    "\n",
    "                param_grid.update({\n",
    "                        'clustering_model__alpha': trial.suggest_categorical('clustering_model__alpha', [0.05, 0.1, 0.15, 0.2, 0.25]),\n",
    "                    })\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_grid_RF_XGB(trial):\n",
    "\n",
    "    param_grid = preprocessing_param_grid(trial)\n",
    "    param_grid.update(param_grid_clustering_model(trial))\n",
    "\n",
    "    n_clusters = param_grid['clustering_model__n_clusters']\n",
    "\n",
    "    for j in range(0, n_clusters): # Create grids only for the effective clusters\n",
    "\n",
    "        # Grids for RF\n",
    "        if j in clusters_RF:\n",
    "\n",
    "            param_grid.update({\n",
    "                f'clustering_model__estimators__{j}__n_estimators': trial.suggest_int(f'clustering_model__estimators__{j}__n_estimators', 50, 120),\n",
    "                f'clustering_model__estimators__{j}__max_depth': trial.suggest_categorical(f'clustering_model__estimators__{j}__max_depth', [None, 3, 5, 7, 10, 20, 30, 40, 50]),\n",
    "                f'clustering_model__estimators__{j}__min_samples_split': trial.suggest_int(f'clustering_model__estimators__{j}__min_samples_split', 2, 25),\n",
    "                f'clustering_model__estimators__{j}__min_samples_leaf': trial.suggest_int(f'clustering_model__estimators__{j}__min_samples_leaf', 2, 25)\n",
    "            })\n",
    "\n",
    "        # Grids for XGB\n",
    "        if j in clusters_XGB:  \n",
    "\n",
    "            param_grid.update({\n",
    "                f'clustering_model__estimators__{j}__max_depth': trial.suggest_categorical(f'clustering_model__estimators__{j}__max_depth', [None, 3, 5, 7, 10, 20, 30, 40, 50]),\n",
    "                f'clustering_model__estimators__{j}__lambda': trial.suggest_float(f'clustering_model__estimators__{j}__lambda', 0, 0.5, step=0.1, log=False),\n",
    "                f'clustering_model__estimators__{j}__n_estimators': trial.suggest_categorical(f'clustering_model__estimators__{j}__n_estimators', [30, 50, 70, 100, 150, 180]),\n",
    "                f'clustering_model__estimators__{j}__eta': trial.suggest_float(f'clustering_model__estimators__{j}__eta', 0, 0.3, step=0.02, log=False),\n",
    "                f'clustering_model__estimators__{j}__alpha': trial.suggest_float(f'clustering_model__estimators__{j}__alpha', 0.2, 1, step=0.01, log=False)\n",
    "            })\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_eval = SimpleEvaluation(estimator=pipeline_fast_kmedoids_estimator,  \n",
    "                                cv=inner, \n",
    "                                param_grid=param_grid_RF_XGB,\n",
    "                                search_method='optuna',\n",
    "                                scoring='neg_mean_absolute_error', \n",
    "                                direction='maximize', \n",
    "                                n_trials=10, \n",
    "                                random_state=666)\n",
    "\n",
    "simple_eval.fit(X=X, y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessing__quant__imputer__method</th>\n",
       "      <th>preprocessing__cat__imputer__method</th>\n",
       "      <th>preprocessing__quant__scaler__apply</th>\n",
       "      <th>preprocessing__cat__encoder__method</th>\n",
       "      <th>features_selector__apply</th>\n",
       "      <th>preprocessing__quant__scaler__method</th>\n",
       "      <th>clustering_model__n_clusters</th>\n",
       "      <th>clustering_model__method</th>\n",
       "      <th>clustering_model__init</th>\n",
       "      <th>clustering_model__frac_sample_size</th>\n",
       "      <th>clustering_model__d1</th>\n",
       "      <th>clustering_model__d2</th>\n",
       "      <th>clustering_model__estimators__0__n_estimators</th>\n",
       "      <th>clustering_model__estimators__0__max_depth</th>\n",
       "      <th>clustering_model__estimators__0__min_samples_split</th>\n",
       "      <th>clustering_model__estimators__0__min_samples_leaf</th>\n",
       "      <th>clustering_model__estimators__1__max_depth</th>\n",
       "      <th>clustering_model__estimators__1__lambda</th>\n",
       "      <th>clustering_model__estimators__1__n_estimators</th>\n",
       "      <th>clustering_model__estimators__1__eta</th>\n",
       "      <th>clustering_model__estimators__1__alpha</th>\n",
       "      <th>clustering_model__estimators__2__n_estimators</th>\n",
       "      <th>clustering_model__estimators__2__max_depth</th>\n",
       "      <th>clustering_model__estimators__2__min_samples_split</th>\n",
       "      <th>clustering_model__estimators__2__min_samples_leaf</th>\n",
       "      <th>clustering_model__estimators__3__max_depth</th>\n",
       "      <th>clustering_model__estimators__3__lambda</th>\n",
       "      <th>clustering_model__estimators__3__n_estimators</th>\n",
       "      <th>clustering_model__estimators__3__eta</th>\n",
       "      <th>clustering_model__estimators__3__alpha</th>\n",
       "      <th>clustering_model__estimators__4__n_estimators</th>\n",
       "      <th>clustering_model__estimators__4__max_depth</th>\n",
       "      <th>clustering_model__estimators__4__min_samples_split</th>\n",
       "      <th>clustering_model__estimators__4__min_samples_leaf</th>\n",
       "      <th>clustering_model__robust_maha_method</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>simple_mean</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>True</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>standard</td>\n",
       "      <td>3</td>\n",
       "      <td>pam</td>\n",
       "      <td>heuristic</td>\n",
       "      <td>0.030</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>sokal</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>51.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-189925.033692</td>\n",
       "      <td>73.682768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple_mean</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>False</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>pam</td>\n",
       "      <td>k-medoids++</td>\n",
       "      <td>0.030</td>\n",
       "      <td>robust_mahalanobis</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.84</td>\n",
       "      <td>54.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAD</td>\n",
       "      <td>-193352.354000</td>\n",
       "      <td>93.964026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>simple_median</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>True</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>min-max</td>\n",
       "      <td>2</td>\n",
       "      <td>pam</td>\n",
       "      <td>k-medoids++</td>\n",
       "      <td>0.015</td>\n",
       "      <td>mahalanobis</td>\n",
       "      <td>sokal</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-194842.623889</td>\n",
       "      <td>66.683697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iterative_mean</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>True</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>min-max</td>\n",
       "      <td>2</td>\n",
       "      <td>alternate</td>\n",
       "      <td>random</td>\n",
       "      <td>0.020</td>\n",
       "      <td>mahalanobis</td>\n",
       "      <td>sokal</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-198370.937385</td>\n",
       "      <td>65.778179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simple_mean</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>False</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>alternate</td>\n",
       "      <td>heuristic</td>\n",
       "      <td>0.020</td>\n",
       "      <td>mahalanobis</td>\n",
       "      <td>sokal</td>\n",
       "      <td>77</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-198629.430744</td>\n",
       "      <td>88.212142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>simple_median</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>False</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>pam</td>\n",
       "      <td>random</td>\n",
       "      <td>0.030</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>sokal</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-209762.624869</td>\n",
       "      <td>77.228467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iterative_mean</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>False</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>alternate</td>\n",
       "      <td>heuristic</td>\n",
       "      <td>0.015</td>\n",
       "      <td>canberra</td>\n",
       "      <td>sokal</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>112.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-209935.432260</td>\n",
       "      <td>139.501305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>simple_median</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>True</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>standard</td>\n",
       "      <td>3</td>\n",
       "      <td>pam</td>\n",
       "      <td>random</td>\n",
       "      <td>0.020</td>\n",
       "      <td>robust_mahalanobis</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>71</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.75</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAD</td>\n",
       "      <td>-226212.430843</td>\n",
       "      <td>74.882898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simple_median</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>True</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>standard</td>\n",
       "      <td>3</td>\n",
       "      <td>pam</td>\n",
       "      <td>random</td>\n",
       "      <td>0.010</td>\n",
       "      <td>mahalanobis</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.29</td>\n",
       "      <td>51.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-249498.494575</td>\n",
       "      <td>63.639676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_median</td>\n",
       "      <td>simple_most_frequent</td>\n",
       "      <td>True</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>False</td>\n",
       "      <td>standard</td>\n",
       "      <td>5</td>\n",
       "      <td>alternate</td>\n",
       "      <td>heuristic</td>\n",
       "      <td>0.020</td>\n",
       "      <td>canberra</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.54</td>\n",
       "      <td>105.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-259158.519557</td>\n",
       "      <td>128.728094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preprocessing__quant__imputer__method  ...        time\n",
       "7                           simple_mean  ...   73.682768\n",
       "1                           simple_mean  ...   93.964026\n",
       "6                         simple_median  ...   66.683697\n",
       "4                        iterative_mean  ...   65.778179\n",
       "2                           simple_mean  ...   88.212142\n",
       "9                         simple_median  ...   77.228467\n",
       "3                        iterative_mean  ...  139.501305\n",
       "8                         simple_median  ...   74.882898\n",
       "5                         simple_median  ...   63.639676\n",
       "0                         simple_median  ...  128.728094\n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_eval.inner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessing__quant__imputer__method': 'simple_mean',\n",
       " 'preprocessing__cat__imputer__method': 'simple_most_frequent',\n",
       " 'preprocessing__quant__scaler__apply': True,\n",
       " 'preprocessing__cat__encoder__method': 'ordinal',\n",
       " 'features_selector__apply': False,\n",
       " 'preprocessing__quant__scaler__method': 'standard',\n",
       " 'clustering_model__n_clusters': 3,\n",
       " 'clustering_model__method': 'pam',\n",
       " 'clustering_model__init': 'heuristic',\n",
       " 'clustering_model__frac_sample_size': 0.03,\n",
       " 'clustering_model__d1': 'minkowski',\n",
       " 'clustering_model__d2': 'sokal',\n",
       " 'clustering_model__estimators__0__n_estimators': 55,\n",
       " 'clustering_model__estimators__0__max_depth': 40,\n",
       " 'clustering_model__estimators__0__min_samples_split': 12,\n",
       " 'clustering_model__estimators__0__min_samples_leaf': 3,\n",
       " 'clustering_model__estimators__1__max_depth': 3,\n",
       " 'clustering_model__estimators__1__lambda': 0.5,\n",
       " 'clustering_model__estimators__1__n_estimators': 30,\n",
       " 'clustering_model__estimators__1__eta': 0.28,\n",
       " 'clustering_model__estimators__1__alpha': 0.54,\n",
       " 'clustering_model__estimators__2__n_estimators': 51,\n",
       " 'clustering_model__estimators__2__max_depth': 40,\n",
       " 'clustering_model__estimators__2__min_samples_split': 4,\n",
       " 'clustering_model__estimators__2__min_samples_leaf': 11}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_eval.inner_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-189925.0336917885"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_eval.inner_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}